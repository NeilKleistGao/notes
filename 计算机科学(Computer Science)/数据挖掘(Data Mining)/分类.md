## 基本概念
分类的一般方法：
+ 监督学习
+ 无监督学习

如果使用训练集来度量准确率，可能会存在过拟合。

## 决策树归纳
内部节点表示属性测试，分支代表测试的输出。树的顶点是根节点。

算法：
+ ID3
+ C4.5
+ CART

基本策略：
+ 选择一种属性选择度量（信息增益或基尼指数）
+ 树从单个节点开始
+ 如果节点中的元组都为同一类，那么该节点变成树叶
+ 否则，确定分裂准则，把元组进行划分，输出分裂点。

属性选择度量：
+ 信息增益（ID3）：`Info(D) = -sum{pi log pi}`，其中`pi`是某个元组属于某一类的概率。用某个属性A进行划分得到的增益`Gain(A) = Info(D) - Info_A(D)`，其中`Info_A(D) = sum{Dj / D * Info(D)}`
+ 增益率(C4.5)：增益率使用`GainRate(A) = Gain(A) / SplitInfo_A(D)`，其中`SplitInfo_A(D) = - sum{Dj / D  * log(Dj / D)}`
+ 基尼指数(CART)：`Gini(D) = 1 - sum{pi^2}`，对于某个属性的划分，`Gini_A(D) = D1 / D * Gini(D1) + D2 / D * Gini(D2)`

树剪枝：
+ 先剪枝：提前停止树的构建
+ 后剪枝：由完全生长的树减去子树

## 模型评估与选择
评估度量：
+ 准确率（识别率）：`(TP + TN) / (P + N)`
+ 错误率（误分类率）：`(FP + FN) / (P + N)`
+ 召回率（敏感度、真正例率）：`TP / P`
+ 特效性（真负例率）：`TN / N`
+ 精度：`TP / (TP + FP)`
+ F1分数：`(2 * precision * recall) / (precision + recall)`
+ F-beta：`((1 + beta^2) * precision * recall) / (beta^2 * precision + recall)`

混淆矩阵：
| | 预测yes | 预测no | 合计
---| --- | --- | --- 
实际yes | TP | FN | P
实际no | FP | TN | N
合计 | P' | N' | P + N

ROC（接收者操作特征）曲线：y轴为召回率，x轴为假正例率，通过设置正例阈值绘制曲线。
